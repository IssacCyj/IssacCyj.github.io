<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Yujia Chen's Homepage</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/agency.css" rel="stylesheet">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">Yujia Chen</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav text-uppercase ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#header">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#education">Education</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#research">Research</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#projects">Projects</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="Resume-YujiaChen.pdf" target="_blank">Resume</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Header -->
    <header class="masthead" id="header">
      <div class="container">
        <div class="intro-text">
         <!--  <div class="intro-lead-in">Welcome To Our Studio!</div>
          <div class="intro-heading text-uppercase">It's Nice To Meet You</div> -->
        
          <div class="row">
            <div class="col-sm-6 offset-sm-1">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/photo.jpg" alt="">
                <h2>Yujia Chen</h2>
                <p class="text-white">Hello my friend, it's nice to meet you here.</p> 
                <p class="text-white">I work as an applied scientist in AmazonGo. Before this, I was a master student in <font size="3" color="#fed136">Computer Vision program at CMU</font>. My research interests mainly include machine learning, computer vision, deep learning and related topics. I have <font size="3" color="#fed136">four publications and several research experiences </font>as you can find in my <a href="YujiaChen-CMU.pdf" target="_blank"><font size="3" color="#fed136">RESUME</font></a>. Feel free to <a href="mailto:yujiac2@cs.cmu.edu" target="_blank"><font size="3" color="#fed136">CONTACT</font></a> me</p>
                <p class="text-white">Hope everything goes well with you. Cheers!</p>

                <ul class="list-inline social-buttons">
                  <li class="list-inline-item">
                    <a href="https://github.com/IssacCyj" target="_blank">
                      <i class="fa fa-github"></i>
                    </a>
                  </li>
                  <li class="list-inline-item">
                    <a href="https://www.linkedin.com:/in/yujia-chen-631905120/" target="_blank">
                      <i class="fa fa-linkedin-square"></i>
                    </a>
                  </li>
                </ul>

              </div>
            </div>
          </div>
          <!-- <a class="btn btn-primary btn-l text-uppercase js-scroll-trigger" href="#education">My projects</a> -->
        </div>
      </div>
    </header>

    <!-- Education -->
    <section id="education">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Education</h2>
            <h3 class="section-subheading text-muted">Learn and Inspire</h3>
          </div>
        </div>
        <div class="row text-center">
          <div class="col-md-6">
            <img class="mx-auto rounded-circle" src="img/universities/CMU.jpg" alt="">
            <h4 class="service-heading">Carnegie Mellon University</h4>
            <p class="text-muted">Master of Science in Computer Vision (MS, Robotics Institute, School of Computer Science, 2018-2019)</p>
          </div>
          <div class="col-md-6">
            <img class="mx-auto rounded-circle" src="img/universities/USTB.jpg" alt="">
            <h4 class="service-heading">University of Science and Technology Beijing</h4>
            <p class="text-muted">Double Major in Internet of Things and Financial Engineering (BS, 2014-2018)</p>
          </div>
        </div>
      </div>
    </section>

    <!-- research Grid -->
    <section class="bg-light" id="research">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Publications</h2>
            <h3 class="section-subheading text-muted">Create and Innovate</h3>
          </div>
        </div>
        <div class="row">
          
          <div class="col-md-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal3">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <h3>BTAS 2018 (oral)</h3>
                </div>
              </div>
              <img class="img-fluid" src="img/research/AOFD2.jpg" alt="">
            </a>
            <div class="portfolio-caption">
              <h5>Adversarial Occlusion-aware Face Detection</h4>
              <p class="text-muted">China Academy of Science, Institute of Automation</p>
            </div>
          </div>
          <div class="col-md-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal4">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <h3>ACPR 2018 (oral)</h3>
                </div>
              </div>
              <img class="img-fluid" src="img/research/GMNet.png" alt="">
            </a>
            <div class="portfolio-caption">
              <h5>Group-merging Network</h4>
              <p class="text-muted">Laboratory of IoT&Robotics@USTB</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section id="projects">
      <div class="container-fluid p-0">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Researches & Projects</h2>
            <h3 class="section-subheading text-muted">Design and Code</h3>
          </div>
        </div>
        <div class="row no-gutters popup-gallery">
          <div class="col-lg-4 col-sm-6">
          <a class="portfolio-box" href="#portfolioModal1" data-toggle="modal" target="_blank">
              <img class="img-fluid" src="img/research/normal.png" alt="">
              <div class="portfolio-box-caption">
                <div class="portfolio-box-caption-content">
                  <div class="project-category text-faded">
                    Drivability Analysis for Autonomous Vehicles
                  </div>
                  <div class="project-name">
                    Deep Slope Estimation with Formal Verification
                  </div>
                </div>
              </div>
            </a>
          </div>
          <div class="col-lg-4 col-sm-6">
          <a class="portfolio-box" href="#portfolioModal2" data-toggle="modal" target="_blank">
              <img class="img-fluid" src="img/research/CPU.jpg" alt="">
              <div class="portfolio-box-caption">
                <div class="portfolio-box-caption-content">
                  <div class="project-category text-faded">
                    Apply Deep Learning Model on Mobile Devices
                  </div>
                  <div class="project-name">
                    Towards CPU Real Time Object detector
                  </div>
                </div>
              </div>
            </a>
          </div>


          <div class="col-lg-4 col-sm-6">
            <a class="portfolio-box" href="#portfolioModal5" data-toggle="modal" target="_blank">
              <img class="img-fluid" src="img/projects/LK0.png" alt="">
              <div class="portfolio-box-caption">
                <div class="portfolio-box-caption-content">
                  <div class="project-category text-faded">
                    Fast object detection without training
                  </div>
                  <div class="project-name">
                    Deep Lucas Kanade Detector
                  </div>
                </div>
              </div>
            </a>
          </div>
          <div class="col-lg-4 col-sm-6">
            <a class="portfolio-box" href="#portfolioModal6" data-toggle="modal" target="_blank">
              <img class="img-fluid" src="img/projects/fish.png" alt="">
              <div class="portfolio-box-caption">
                <div class="portfolio-box-caption-content">
                  <div class="project-category text-faded">
                    Kaggle Competition (Computer Vision)
                  </div>
                  <div class="project-name">
                    The Nature Conservancy Fisheries Monitoring
                  </div>
                </div>
              </div>
            </a>
          </div>
          <div class="col-lg-4 col-sm-6">
            <a class="portfolio-box" href="#portfolioModal7" data-toggle="modal" target="_blank">
              <img class="img-fluid" src="img/projects/bio0.png" alt="">
              <div class="portfolio-box-caption">
                <div class="portfolio-box-caption-content">
                  <div class="project-category text-faded">
                    Molecular BioSystems 16' (Data Science)
                  </div>
                  <div class="project-name">
                    miRNA–EF interactions inference based on the random walk with restart
                  </div>
                </div>
              </div>
            </a>
          </div>
          <div class="col-lg-4 col-sm-6">
            <a class="portfolio-box" href="#portfolioModal8" data-toggle="modal" target="_blank">
              <img class="img-fluid" src="img/projects/tellmeeye.png" alt="">
              <div class="portfolio-box-caption">
                <div class="portfolio-box-caption-content">
                  <div class="project-category text-faded">
                    Wearable Device for Blind People (Computer Vision and System)
                  </div>
                  <div class="project-name">
                    Tell Me Eye Smart Glasses
                  </div>
                </div>
              </div>
            </a>
          </div>
          <div class="col-lg-4 col-sm-6">
            <a class="portfolio-box" href="#portfolioModal9" data-toggle="modal" target="_blank">
              <img class="img-fluid" src="img/projects/health.png" alt="">
              <div class="portfolio-box-caption">
                <div class="portfolio-box-caption-content">
                  <div class="project-category text-faded">
                   Data Mining
                  </div>
                  <div class="project-name">
                  Human Health and Climate Change Relation Model
                  </div>
                </div>
              </div>
            </a>
          </div>
          <div class="col-lg-4 col-sm-6">
            <a class="portfolio-box" href="https://github.com/IssacCyj" target="_blank">
              <img class="img-fluid" src="img/projects/blank.png" alt="">
              <div class="portfolio-box-caption">
                <div class="portfolio-box-caption-content">
                  <div class="project-name">
                    More on GitHub
                  </div>
                </div>
              </div>
            </a>
          </div>
          <!-- <div class="col-lg-4 col-sm-6">
            <a class="portfolio-box" href="img/portfolio/fullsize/6.jpg">
              <img class="img-fluid" src="img/portfolio/thumbnails/6.jpg" alt="">
              <div class="portfolio-box-caption">
                <div class="portfolio-box-caption-content">
                  <div class="project-category text-faded">
                    AI
                  </div>
                  <div class="project-name">
                    Ultimate Tic-Tac-Toe
                  </div>
                </div>
              </div>
            </a>
          </div> -->
        </div>
      </div>
    </section>

    


    <!-- Footer -->
    <footer>
      <div class="container">
        <div class="row">
          <div class="col-md-4">
            <span class="copyright">Copyright &copy; Yujia Chen 2019</span>
          </div>
          <!-- <div class="col-md-4">
            <ul class="list-inline social-buttons">
              <li class="list-inline-item">
                <a href="#">
                  <i class="fa fa-twitter"></i>
                </a>
              </li>
              <li class="list-inline-item">
                <a href="#">
                  <i class="fa fa-facebook"></i>
                </a>
              </li>
              <li class="list-inline-item">
                <a href="#">
                  <i class="fa fa-linkedin"></i>
                </a>
              </li>
            </ul>
          </div> -->
         <!--  <div class="col-md-4">
            <ul class="list-inline quicklinks">
              <li class="list-inline-item">
                <a href="#">Privacy Policy</a>
              </li>
              <li class="list-inline-item">
                <a href="#">Terms of Use</a>
              </li>
            </ul>
          </div> -->
        </div>
      </div>
    </footer>

    <!-- Portfolio Modals -->

    <!-- Modal 1 -->
    <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-10 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Deep Slope Estimation with Formal Verification</h2>
                  <p class="item-intro text-muted">Carnegie Mellon University & HRL Laboratories</p>
                  <img class="img-fluid d-block mx-auto" src="img/research/normal.png" alt="">
                  <p class="description">In order to drive safely, autonomous vehicles need to estimate the slope of the terrain on which the vehicle intends to drive. This is necessary to determine which parts of the terrain are drivable and to avoid obstacles. Thus, estimating the slope and drivability of the terrain is crucial for safe autonomous driving. Our solution is to use deep slope estimation with formal verification. We will train a neural network to quickly estimate the slope at all points of a large terrain. We will then compress the model to make it analyzable for formal verification methods. This combination of deep learning with formal verification will allow our method to be both fast and provably accurate.</p>
                  <ul class="list-inline">
                    <li>Website: https://mscvprojects.ri.cmu.edu/2019teamf</li>
                    <li>Code: https://github.com/IssacCyj</li>
                    <li>Category: Computer Vision, Machine Learning</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 2 -->
    <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-10 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Towards CPU Real Time Object Detector</h2>
                  <p class="item-intro text-muted">Carnegie Mellon University</p>
                  <img class="img-fluid d-block mx-auto" src="img/research/CPU.jpg" alt="">
                  <p class="description">In recent years, the trade-off between accuracy and speed in detection has been widely researched. As many single-stage detectors have achieved remarkable performance on both sides, the performance of CPU real-time detectors is still far from satisfaction. In this project, we design a CPU real-time detector based on SSD baseline. First, we train a teacher network which has high accuracy based on SSD and FPN. Then we do model compression using knowledge distillation with MobileNet+SSD as student network which is much faster while maintaining the accuracy. Experiment results demonstrate that our proposed methods could increase detection results of the tiny student network especially on hard classes like tiny or occluded objects.</p>
                  <ul class="list-inline">
                    <li>Code: https://github.com/IssacCyj</li>
                    <li>Category: Computer Vision, Model Compression</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 3 -->
    <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-10 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Adversarial Occlusion-aware Face Detection</h2>
                  <p class="item-intro text-muted">China Academy of Science, Institute of Automation</p>
                  <img class="img-fluid d-block mx-auto" src="img/research/AOFD2.jpg" alt="">
                  <p class="description">Occluded face detection is a challenging detection task due to the large appearance variations incurred by various real-world occlusions. This paper introduces an Adversarial Occlusion-aware Face Detector (AOFD) by simultaneously detecting occluded faces and segmenting occluded areas. Specifically, we employ an adversarial training strategy to generate occlusion-like face features that are difficult for a face detector to recognize. Occlusion is predicted simultaneously while detecting occluded faces and the occluded area is utilized as an auxiliary instead of being regarded as a hindrance. Moreover, the supervisory signals from the segmentation branch will reversely affect the features, helping extract more informative features. Consequently, AOFD is able to find the faces with few exposed facial landmarks with very high confidences and keeps high detection accuracy even for masked faces. Extensive experiments demonstrate that AOFD not only significantly outperforms state-of-the-art methods on the MAFA occluded face detection dataset, but also achieves competitive detection accuracy on benchmark dataset for general face detection such as FDDB.</p>
                  <ul class="list-inline">
                    <li>paper: https://arxiv.org/abs/1709.05188</li>
                    <li>Code: https://github.com/IssacCyj/Adversarial-Occlussion-aware-Face-Detection</li>
                    <li>Category: Computer Vision, Deep Learning</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 4 -->
    <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-10 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Group-merging Network</h2>
                  <p class="item-intro text-muted">Laboratory of IoT&Robotics@USTB</p>
                  <img class="img-fluid d-block mx-auto" src="img/research/GMNet.png" alt="">
                  <p>Deep Convolutional Neural Networks (CNNs) are capable of learning unprecedentedly effective features from images. Some researchers have struggled to enhance the parameters' efficiency using grouped convolution. However, the relation between the optimal number of convolutional groups and the recognition performance remains an open problem. In this paper, we propose a series of Basic Units (BUs) and a two-level merging strategy to construct deep CNNs, referred to as a joint Grouped Merging Net (GM-Net), which can produce joint grouped and reused deep features while maintaining the feature discriminability for classification tasks. Our GM-Net architectures with the proposed BU\_A (dense connection) and BU\_B (straight mapping) lead to significant reduction in the number of network parameters and obtain performance improvement in image classification tasks. Extensive experiments are conducted to validate the superior performance of the GM-Net than the state-of-the-arts on the benchmark datasets, e.g., MNIST, CIFAR-10, CIFAR-100 and SVHN.</p>
                  <ul class="list-inline">
                    <li>paper: hhttps://arxiv.org/abs/1706.06792</li>
                    <li>Code: https://github.com/IssacCyj/GM-Net</li>
                    <li>Category: Model Compression, Deep Learning</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 5 -->
    <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-10 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Deep Lucas Kanade Detector</h2>
                  <p class="item-intro text-muted">Carnegie Mellon University</p>
                  <img class="img-fluid d-block mx-auto" src="img/projects/LK0.png" alt="">
                  <p>Lucas Kanade algorithm is a classical object tracking method. It computes the current location of an object based on the previous templates. As it directly calculate the first order derivates on the original image level, this algorithm runs pretty fast. In this project, we convert detection problem into a template tracking problem. Specifically, each anchor lcation of the feature map should try to match the template, and we compute a current bounding box for each anchor. If the shifts and loss are less than a threshold, then it is regareded as a true prediction. Only a pretrained feature extractor is required for the whole pipeline and there is no training procedure, no regresion branch and no classifcation branch. The proposed method has two assumptions: 1. LK algorithm assumes minor shift of the object; 2. We only have one template for all the objects that belongs to a class which requires the intra class variance of the features extracted from the deep learning model to be very small. </p>
                  <ul class="list-inline">
                    <li>Date: Fall 2018</li>
                    <li>Category: Deep Learning, Object Detection</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 6 -->
    <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-10 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">The Nature Conservancy Fisheries Monitoring</h2>
                  <p class="item-intro text-muted">Kaggle Compitition</p>
                  <img class="img-fluid d-block mx-auto" src="img/projects/fish.png" alt="">
                  <p>The task of this competition is to develop algorithms to automatically detect and classify species of tunas, sharks and more that fishing boats catch, which will accelerate the video review process. Faster review and more reliable data will enable countries to reallocate human capital to management and enforcement activities which will have a positive impact on conservation and our planet. However, the difficaulty is that the quality of the collect images on the fish boat is very poor and the fish appears to be quite blurry in many scenes. We propose a foreground-background merging method which enlarges effective receptive field and classifcation information. The rank of our team is top 20% in the first round.</p>
                  <ul class="list-inline">
                    <li>Date: August 2017</li>
                    <li>Category: Deep Learning</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

        <!-- Modal 7 -->
    <div class="portfolio-modal modal fade" id="portfolioModal7" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-10 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">miRNA–EF interactions inference based on the random walk with restart</h2>
                  <p class="item-intro text-muted">Reimplementation of the paper: miREFRWR: a novel disease-related microRNA- environmental factor interactions prediction method</p>
                  <img class="img-fluid d-block mx-auto" src="img/projects/bio0.png" alt="">
                  <p>Increasing evidence has indicated that microRNAs (miRNAs) can functionally interact with environmental factors (EFs) to affect and determine human diseases. Uncovering the potential associations between diseases and miRNA–EF interactions could benefit the understanding of the underlying disease mechanism at miRNA and EF levels, miRNA signatures identification, and drug repurposing. In this study, based on the assumption that similar miRNAs (EFs) tend to interact with similar EFs (miRNAs) in the context of a given disease and under the framework of random walk with restart (RWR), a novel method of miREFRWR was developed to uncover the hidden disease-related miRNA–EF interactions by implementing random walks on an miRNA similarity network and EF similarity network, respectively. miREFRWR was evaluated by leave-one-out cross-validation, which achieved an AUC of 0.9500. It has been demonstrated that miREFRWR can effectively identify potential interactions in all the test classes, even if these test samples only share either EFs or miRNAs with the training samples. Furthermore, many predictive results for acute promyelocytic leukemia and breast cancer (67 and 10 interactions out of the top 1% predictions, respectively) have been verified by independent experimental studies. It is anticipated that miREFRWR could be a useful and important biological resource for biomedical research.</p>
                  <ul class="list-inline">
                    <li>Paper Link: https://www.ncbi.nlm.nih.gov/pubmed/26689259</li>
                    <li>Date: October 2017</li>
                    <li>Category: Biological Data Analysis</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

        <!-- Modal 8 -->
    <div class="portfolio-modal modal fade" id="portfolioModal8" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-10 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Tell Me Eye Smart Glasses</h2>
                  <p class="item-intro text-muted">Wearable devices designed for the blind people.</p>
                  <img class="img-fluid d-block mx-auto" src="img/projects/tellmeeye.png" alt="">
                  <p>This project is to convert the real world visual signal to sudio signal to help the plind people fell the surrounding better. We designed a smart glasses that is able to "tell" blind people what is going on around them. Specifically, we use raspberry zero W to process the real world data and transmitting the data to the server. After getting the description of the collected images (videos) with image caption models, the smart glass is able to tell the blind people about the surroundings around them.</p>
                  <ul class="list-inline">
                    <li>Date: January 2017</li>
                    <li>Category: Deep learning, System Design</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

        <!-- Modal 9 -->
    <div class="portfolio-modal modal fade" id="portfolioModal9" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-10 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Human Health and Climate Change Relation Model</h2>
                  <p class="item-intro text-muted">University of Science and Technology Beijing</p>
                  <img class="img-fluid d-block mx-auto" src="img/projects/health.png" alt="">
                  <p>Health of human beings is influenced by multi-factors, among which weather conditions, API and so on are the most salient ones. Therefore, it is a popular theme to explore the relation between human health and these factors. In this article, we first propose a cluster-analyzing method based on weather conditions, finding its inner relation with API. Furthermore, with correlation analysis and time series analysis, taking the consideration of weather conditions, API and the number of patients for specific diseases, we eventually arrive at some comprehensive conclusions. At the last part of our methods, we propose a L2-Least Square Method model to predict the approximate number of patients for specific diseases, gaining a high precision rate after cross validation.</p>
                  <ul class="list-inline">
                    <li>Date: May 2017</li>
                    <li>Category: Data Mining</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>


    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Contact form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/agency.min.js"></script>

  </body>

</html>
